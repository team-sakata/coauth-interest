{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T10:28:25.298226Z",
     "iopub.status.busy": "2024-06-25T10:28:25.297674Z",
     "iopub.status.idle": "2024-06-25T10:28:25.306508Z",
     "shell.execute_reply": "2024-06-25T10:28:25.306012Z",
     "shell.execute_reply.started": "2024-06-25T10:28:25.298204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/disks/qnap3/users/23-miura/coauth-interest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "data_path = os.getenv('DATA_PATH')\n",
    "result_path = os.getenv('RESULT_PATH')\n",
    "\n",
    "root = os.getenv('ROOT')\n",
    "\n",
    "os.chdir(root)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T10:29:51.681502Z",
     "iopub.status.busy": "2024-06-25T10:29:51.681023Z",
     "iopub.status.idle": "2024-06-25T10:29:51.688725Z",
     "shell.execute_reply": "2024-06-25T10:29:51.688116Z",
     "shell.execute_reply.started": "2024-06-25T10:29:51.681475Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import random\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import pareto\n",
    "import tqdm\n",
    "\n",
    "from source.package.util import plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T10:30:54.357240Z",
     "iopub.status.busy": "2024-06-25T10:30:54.356378Z",
     "iopub.status.idle": "2024-06-25T10:31:02.602722Z",
     "shell.execute_reply": "2024-06-25T10:31:02.601691Z",
     "shell.execute_reply.started": "2024-06-25T10:30:54.357207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14929032</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14878212</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14852370</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14865167</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14878213</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          year\n",
       "eid           \n",
       "14929032  1970\n",
       "14878212  1970\n",
       "14852370  1970\n",
       "14865167  1970\n",
       "14878213  1970"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_df = pd.DataFrame(pd.read_pickle(data_path+\"/paper_detail/year.pickle\")).sort_values(by=\"year\",ascending=True)\n",
    "year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T10:32:51.672818Z",
     "iopub.status.busy": "2024-06-25T10:32:51.672430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file of discipline So\n",
      "completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████▋   | 917/1000 [06:47<00:38,  2.18it/s]"
     ]
    }
   ],
   "source": [
    "def calculate_coauth_intervals(id,authors_valid,year_df):\n",
    "    works = authors_valid['eid'][authors_valid['authid']==id]\n",
    "    if works.shape[0]<3: return None\n",
    "\n",
    "    selected_papers = year_df[year_df.index.isin(works.values)]\n",
    "    selected_papers = selected_papers.assign(seq=list(range(0,len(selected_papers))))\n",
    "    coauthors = authors_valid[authors_valid['eid'].isin(works)].query(f\"authid!={id}\")\n",
    "    \n",
    "    df_seqyear = pd.merge(coauthors,selected_papers, how='left', on='eid').sort_values(by='seq')\n",
    "    df_seqyear_multi = df_seqyear.groupby(by='authid', group_keys=True).filter(lambda x: len(x) > 1)\n",
    "    if len(df_seqyear_multi) < 1: return None\n",
    "    df_seqyear_delta = df_seqyear_multi.groupby(by='authid', group_keys=True)[['year','seq']] \\\n",
    "    .apply(lambda x:  x - x.shift(1)) \\\n",
    "    .dropna().astype(int).reset_index()\n",
    "    \n",
    "    df_seqyear_delta = pd.merge(df_seqyear_delta, df_seqyear[\"eid\"], how=\"left\", left_on=\"level_1\", right_index=True).drop(columns=[\"level_1\"])\n",
    "    df_seqyear_delta[\"source_authid\"] = id\n",
    "    df_seqyear_delta[\"previous_work\"] = df_seqyear_delta.groupby(\"authid\").shift(1)[\"eid\"]\n",
    "\n",
    "    df_seqyear_delta = df_seqyear_delta.dropna()\n",
    "    return df_seqyear_delta\n",
    "\n",
    "num_iterations = 5\n",
    "batch_size = 1000\n",
    "\n",
    "partitions = pd.read_pickle(result_path+\"partitions_id_lookup.pickle\")\n",
    "disciplines = partitions[\"name\"]\n",
    "\n",
    "for d in disciplines:\n",
    "    print(f\"Loading file of discipline {d}\")\n",
    "    authors_valid= pd.read_pickle(result_path+f\"/authors_valid_{d}.pickle\")\n",
    "    sample_authors = pd.read_pickle(result_path+f\"/sample_authors_{d}.pickle\")\n",
    "    print(\"completed\")\n",
    "    for i in range(num_iterations):\n",
    "        result = pd.DataFrame()\n",
    "        for j in tqdm.tqdm(range(batch_size)):\n",
    "            result = pd.concat([result, calculate_coauth_intervals(sample_authors[i*batch_size+j],authors_valid,year_df)],axis=0)\n",
    "        result.to_pickle(result_path+f\"/temp/{d}_{i:02}.pickle\")\n",
    "    \n",
    "    auth = pd.concat([pd.read_pickle(result_path+f\"/temp/{d}_{i:02}.pickle\") for i in range(0,num_iterations)],axis=0)\n",
    "    auth.to_pickle(result_path+f\"/{d}_5k.pickle\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(disciplines):\n",
    "    auth = pd.read_pickle(f\"./result/{d}_100k.pickle\")\n",
    "    # auth = pd.concat([pd.read_pickle(f\"./result/{disc}_{i:02}.pickle\") for i in range(70,100)],axis=0)\n",
    "    print(\"In \",d,\":...#Unique Authors Examined: \",len(auth[\"source_authid\"].unique())) # number of unique authors examined\n",
    "    print(\"...aggregatedly coauth with \",len(auth[\"authid\"].unique()),\"unique researchers\") # number of unique authors of 100k researcher did coauthor\n",
    "    print(\"...aggregatedly produced\",len(auth[\"eid\"].unique()),\"papers\") # number of unique papers of 100k researcher did coauthor\n",
    "\n",
    "    color = plt.cm.viridis(i / (len(disciplines) - 1))\n",
    "    # color = \"blue\"\n",
    "    unique_coauth_researchers = auth.groupby(\"source_authid\")[\"authid\"].apply(lambda x: len(x.unique()))\n",
    "    plotter(unique_coauth_researchers,\\\n",
    "            u=\"people\",\\\n",
    "            count=\"probability\",\\\n",
    "            plot=\"log\",\n",
    "            l=d,\\\n",
    "            title=\"Distribution - number of unique auth pairs\",\\\n",
    "            c=color,\\\n",
    "            line=True,\\\n",
    "            xlabel=\"number of unique auth pairs\")\n",
    "    plt.ylim(top=0.3)\n",
    "    print(\"Average researcher coauth with \",round(unique_coauth_researchers.mean(),2),\"researchers on average\") # average number of unique coauthor per researcher\n",
    "    print(\"Average researcher coauth \",round(len(auth)/len(auth[\"source_authid\"].unique()),2),\" times in total\") # average number of re-coauthorships per researcher\n",
    "    print(\"Coauth persist \", round(len(auth)/(len(auth[\"source_authid\"].unique())*unique_coauth_researchers.mean()),2),\" times on average\") # average number of re-coauthorships per researhcer per unique coauthor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
