{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot  as plt\n","import random\n","\n","from scipy.stats import expon\n","from scipy.stats import pareto"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["p=0.76\n","q=0.82\n","m=3\n","\n","C_HIS = {0:{1,2},1:{0,2},2:{0,1}}\n","INC = {0,1,2}\n","coauth = []\n","\n","def step():\n","  max_id = len(INC)\n","  id = set()\n","  inc_his = [] # team of previously selected agent\n","  \n","  while len(id)<m:\n","    # incumbents\n","    if random.random()<p:\n","      if random.random()<q and len(inc_his)!=0:\n","        choice =random.choice(list(inc_his))\n","      else:\n","        choice =random.choice(list(INC))\n","      id.add(choice)\n","      inc_his = C_HIS[choice]\n","    # newcomer\n","    else:\n","      id.add(max_id)# ID of the newcomer\n","      max_id += 1\n","  \n","  for i in id:\n","    if C_HIS.get(i)!=None:\n","      C_HIS[i].update(id - {i})\n","    else:\n","      C_HIS.update([(i,id - {i})])\n","  INC.update(id)\n","  return id\n","\n","for i in range(10000):\n","  coauth.append(step())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["temp = pd.DataFrame(coauth).rename_axis(\"eid\")\n","num_works = 200\n","\n","def combine_columns(row):\n","    return row.values.tolist()\n","\n","# author_df = temp.iterrows.values.tolist()\n","author_df = pd.DataFrame(temp.apply(combine_columns, axis=1).rename(\"authid\"))\n","author_df = author_df.assign(year=[i // num_works for i in range(author_df.shape[0])])\n","author_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from util import plotter\n","\n","authors_valid = author_df.explode(\"authid\").reset_index()\n","authors_valid\n","# coauthorship_count = authors_valid[['eid', 'authid']].groupby(by='authid').count()\n","# big_author = coauthorship_count.rename({\"eid\":\"n_papers\"},axis=1)\n","# big_author\n","# # plotter(big_author[\"n_papers\"], count=\"number\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def coauthor_works(id):\n","    works = authors_valid[\"eid\"][authors_valid['authid']==id]\n","    \n","    coauthors = authors_valid[authors_valid['eid'].isin(works)].query(f\"authid!={id}\")\n","    df_seqyear_multi = coauthors.groupby(by='authid', group_keys=True).filter(lambda x: len(x) > 1)\n","    if len(df_seqyear_multi)<1: return None\n","    df_seqyear_delta = df_seqyear_multi.groupby(by='authid', group_keys=True)['year'] \\\n","    .apply(lambda x: x - x.shift(1)) \\\n","    .dropna().reset_index().rename(columns={\"level_1\":\"eid\"})\n","    \n","    df_seqyear_delta[\"source_authid\"] = id\n","    df_seqyear_delta[\"previous_work\"] = df_seqyear_delta.groupby(\"authid\").shift(1)[\"eid\"]\n","    \n","    df_seqyear_delta = df_seqyear_delta.dropna()\n","    return df_seqyear_delta\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res = pd.DataFrame()\n","auth_list = [i for i in range(authors_valid[\"authid\"].max())]\n","auth_list = random.sample(auth_list,len(auth_list))\n","for i in range(1000):\n","  res = pd.concat([res,coauthor_works(auth_list[i])],axis=\"index\")\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plotter(res[\"eid\"].nunique(),count=\"number\")\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plotter(authors_valid.groupby(\"authid\")[\"eid\"].nunique(),count=\"number\")\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":2}
